<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Project 5: Fun With Diffusion Models!</title>
    <link rel="stylesheet" href="../assets/css/style.css">
    
    <!-- MathJax for rendering mathematical equations -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/MathJax.js?config=TeX-MML-AM_CHTML"></script>
    
    <style>
        .equation-container {
            margin: 2rem 0;
            padding: 1.5rem;
            background-color: #f5f5f5;
            border-radius: 8px;
            overflow-x: auto;
        }
        
        .equation-container .MathJax {
            font-size: 1.2em;
        }
    </style>
</head>
<body>
    <header>
        <nav>
            <h1><a href="../index.html" class="home-link">Yiqin Huang</a></h1>
            <a href="../index.html#projects">Back to Projects</a>
        </nav>
    </header>

    <main class="container project-page">
        <h2>Project 5: Fun With Diffusion Models!</h2>
        
        <hr>

        <h2>Part A: The Power of Diffusion Models!</h2>

        <h3>Part 0: DeepFloyd!</h3>

        <h4>20 Inference Steps</h4>

        <div class="results-gallery">
            <figure>
                <img src="https://Yiqinh.github.io/pictures/proj_5/generated_images/steps_20/download.png" class="profile-pic">
                <figcaption>a Formula 1 race car</figcaption>
            </figure>
            <figure>
                <img src="https://Yiqinh.github.io/pictures/proj_5/generated_images/steps_20/download (1).png" class="profile-pic">
                <figcaption>two Formula 1 race cars racing side by side</figcaption>
            </figure>
            <figure>
                <img src="https://Yiqinh.github.io/pictures/proj_5/generated_images/steps_20/download (2).png" class="profile-pic">
                <figcaption>an airplane taking off</figcaption>
            </figure>
            <figure>
                <img src="https://Yiqinh.github.io/pictures/proj_5/generated_images/steps_20/download (3).png" class="profile-pic">
                <figcaption>two airplanes taking off side by side</figcaption>
            </figure>
            <figure>
                <img src="https://Yiqinh.github.io/pictures/proj_5/generated_images/steps_20/download (4).png" class="profile-pic">
                <figcaption>Apple iPhone 30 pro max</figcaption>
            </figure>
            <figure>
                <img src="https://Yiqinh.github.io/pictures/proj_5/generated_images/steps_20/download (5).png" class="profile-pic">
                <figcaption>Mango flavored ice cream</figcaption>
            </figure>
        </div>

        <h4>100 Inference Steps</h4>

        <div class="results-gallery">
            <figure>
                <img src="https://Yiqinh.github.io/pictures/proj_5/generated_images/steps_100/download (6).png" class="profile-pic">
                <figcaption>a Formula 1 race car</figcaption>
            </figure>
            <figure>
                <img src="https://Yiqinh.github.io/pictures/proj_5/generated_images/steps_100/download.png" class="profile-pic">
                <figcaption>two Formula 1 race cars racing side by side</figcaption>
            </figure>
            <figure>
                <img src="https://Yiqinh.github.io/pictures/proj_5/generated_images/steps_100/download (1).png" class="profile-pic">
                <figcaption>an airplane taking off</figcaption>
            </figure>
            <figure>
                <img src="https://Yiqinh.github.io/pictures/proj_5/generated_images/steps_100/download (2).png" class="profile-pic">
                <figcaption>two airplanes taking off side by side</figcaption>
            </figure>
            <figure>
                <img src="https://Yiqinh.github.io/pictures/proj_5/generated_images/steps_100/download (3).png" class="profile-pic">
                <figcaption>Apple iPhone 30 pro max</figcaption>
            </figure>
            <figure>
                <img src="https://Yiqinh.github.io/pictures/proj_5/generated_images/steps_100/download (4).png" class="profile-pic">
                <figcaption>Mango flavored ice cream</figcaption>
            </figure>
        </div>

        <p> *Random Seed: 67</p>

        <h4>Thoughts</h4>

        <p>
            The number of inference steps significantly influences the quality of the output. While a mere 20 steps is enough to get the general idea of the prompt, 
            the model is oftentimes hallucinating artifacts and mixing up different ideas in the prompt. The geometry of the image is often distorted and conflicted. 
            When the inference steps is up to 100, the quality significantly improves. The distorted look of the earlier images is almost completely gone. All the pictures look more realistic.
            However, I noticed that the generated images look much closer to training images (existing pictures) than what I am describing in the prompts. Maybe there is slight overfitting here.
        </p>

        <hr>

        <h3>Part 1: Sampling Loops</h3>

        <h4>1.1 Implementing the Forward Process</h4>

        <p> 
            In this part, we add noise to the clean image.
        </p>

        <div class="results-gallery">
            <figure>
                <img src="https://Yiqinh.github.io/pictures/proj_5/noise_0.png" class="profile-pic">
                <figcaption>T = 0</figcaption>
            </figure>
            <figure>
                <img src="https://Yiqinh.github.io/pictures/proj_5/noise_250.png" class="profile-pic">
                <figcaption>T = 250</figcaption>
            </figure>
            <figure>
                <img src="https://Yiqinh.github.io/pictures/proj_5/noise_500.png" class="profile-pic">
                <figcaption>T = 500</figcaption>
            </figure>
            <figure>
                <img src="https://Yiqinh.github.io/pictures/proj_5/noise_750.png" class="profile-pic">
                <figcaption>T = 750</figcaption>
            </figure>
        </div>

        <h4>1.2 Classical Denoising</h4>

        <p>
            In this part, we attempt to use gaussian blurring to clean the noise we added. However, a lot of detail is lost and the image is not
        </p>

        <div class="results-gallery">
            <figure>
                <img src="https://Yiqinh.github.io/pictures/proj_5/noisy_250.png" class="pic">
                <figcaption></figcaption>
            </figure>
        </div>

        <h4>1.3 One-Step Denoising</h4>

        <p>In this part, we use a pretrained diffusion model to denoise our images. However, we only use one denoising step.</p>

        <div class="results-gallery">
            <figure>
                <img src="https://Yiqinh.github.io/pictures/proj_5/one_step.png" class="pic">
                <figcaption>One Step Denoise Comparison</figcaption>
            </figure>
        </div>


        <h4>1.4 Iterative Denoising</h4>

        <p>
            I implemented a "strided" denoising loop to iteratively clean images. 
            This involved writing a function that iteratively applied the denoising formula to visualize the gradual improvement from noise to a clear image.
        </p>
        
        <div class="results-gallery">
            <figure>
                <img src="https://Yiqinh.github.io/pictures/proj_5/iter_denoise.png" class="pic">
                <figcaption>Iterative Denoise Progression Every 5th Loop</figcaption>
            </figure>
        </div>
        <div class="results-gallery">
            <figure>
                <img src="https://Yiqinh.github.io/pictures/proj_5/one_step_final.png" class="profile-pic">
                <figcaption>One Step Denoising</figcaption>
            </figure>
            <figure>
                <img src="https://Yiqinh.github.io/pictures/proj_5/gauss_final.png" class="profile-pic">
                <figcaption>Gaussian Blur</figcaption>
            </figure>
        </div>

        <h4>1.5 Diffusion Model Sampling</h4>

        <p>
            In this part, we sample a pretrained diffusion model starting from pure noise and the prompt: "a high quality photo".
            We iteratively denoise to get the generated image. As you can see, the results are not perfect.
        </p>

        <div class="results-gallery">
            <figure>
                <img src="https://Yiqinh.github.io/pictures/proj_5/denoise_sample_naive.png" class="pic">
                <figcaption>5 Sampled Images (No CFG) </figcaption>
            </figure>
        </div>

        <h4>1.6 Classifier-Free Guidance (CFG)</h4>

        <p>
            In this part, I implemented Classifier-Free Guidance (CFG) to fix 
            the low quality of the previous images. 
            I updated the denoising function to calculate a weighted mix of conditional and unconditional noise estimates.
            I use a null prompt for the unconditioned denoising.
        </p>

        <div class="results-gallery">
            <figure>
                <img src="https://Yiqinh.github.io/pictures/proj_5/cfg_sample.png" class="pic">
                <figcaption>5 Sampled Images with CFG (Scale=7) </figcaption>
            </figure>
        </div>

        <h4>1.7 Image-to-image Translation</h4>

        <p>
            In this part, I edit images by adding specific amounts of noise and then running the iterative denoising process to force them back onto the natural image manifold. 
            This technique relies on the model's ability to "hallucinate" new details during reconstruction, allowing for creative edits based on how much noise was initially added.
        </p>


        <div class="results-gallery">
            <figure>
                <img src="https://Yiqinh.github.io/pictures/proj_5/image_translation.png" class="pic">
                <figcaption>Edits of the Campanile</figcaption>
            </figure>
        </div>

        <h4>1.7.1 Editing Hand-Drawn and Web Images</h4>

        <p>
            In this part, I try image translation with images from the web as well as hand drawn images. I use the prompt, "a high quality photo"
        </p>

        <div class="results-gallery">
            <figure>
                <img src="https://Yiqinh.github.io/pictures/proj_5/pepe_translation.png" class="pic">
                <figcaption>Edits of Pepe image from the Web</figcaption>
            </figure>
        </div>

        <div class="results-gallery">
            <figure>
                <img src="https://Yiqinh.github.io/pictures/proj_5/sus.png" class="pic">
                <figcaption>Edits of Hand Drawn Among Us</figcaption>
            </figure>
        </div>

        <div class="results-gallery">
            <figure>
                <img src="https://Yiqinh.github.io/pictures/proj_5/car.png" class="pic">
                <figcaption>Edits of Hand Drawn Car</figcaption>
            </figure>
        </div>

        <h4>1.7.2 Inpainting</h4>

        <p>
            In this section, I use a binary mask to generate new content in parts of the image.
        </p>

        <div class="results-gallery">
            <figure>
                <img src="https://Yiqinh.github.io/pictures/proj_5/campanile.png" class="pic">
                <figcaption>Original</figcaption>
            </figure>
            <figure>
                <img src="https://Yiqinh.github.io/pictures/proj_5/inpainted_campanile.png" class="pic">
                <figcaption>Inpainted Campanile</figcaption>
            </figure>
        </div>

        <p>
            More of my own masks...
        </p>

        <div class="results-gallery">
            <figure>
                <img src="https://Yiqinh.github.io/pictures/proj_5/pine_mask.png" class="pic">
                <figcaption>Mask Used</figcaption>
            </figure>
        </div>

        <div class="results-gallery">
            <figure>
                <img src="https://Yiqinh.github.io/pictures/proj_5/pineapple_original.png" class="pic">
                <figcaption>Original</figcaption>
            </figure>
            <figure>
                <img src="https://Yiqinh.github.io/pictures/proj_5/pineapple_inpainted.png" class="pic">
                <figcaption>Inpainted Pineapple</figcaption>
            </figure>
        </div>


        <div class="results-gallery">
            <figure>
                <img src="https://Yiqinh.github.io/pictures/proj_5/tank_mask.png" class="pic">
                <figcaption>Mask Used</figcaption>
            </figure>
        </div>

        <div class="results-gallery">
            <figure>
                <img src="https://Yiqinh.github.io/pictures/proj_5/tank.png" class="pic">
                <figcaption>Original</figcaption>
            </figure>
            <figure>
                <img src="https://Yiqinh.github.io/pictures/proj_5/tank_impainted.png" class="pic">
                <figcaption>Inpainted Tank</figcaption>
            </figure>
        </div>

        <h4>1.7.3 Text-Conditional Image-to-image Translation</h4>

        <p>
            In this next part, I modify images by denoising the existing images using a new prompt.
        </p>

        <div class="results-gallery">
            <figure>
                <img src="https://Yiqinh.github.io/pictures/proj_5/missile.png" class="pic">
                <figcaption>Edit Prompt: "A missle launching"</figcaption>
            </figure>
        </div>

        <div class="results-gallery">
            <figure>
                <img src="https://Yiqinh.github.io/pictures/proj_5/colorful_bird.png" class="pic">
                <figcaption>Edit Prompt: "a colorful bird"</figcaption>
            </figure>
        </div> 
        
        <div class="results-gallery">
            <figure>
                <img src="https://Yiqinh.github.io/pictures/proj_5/balloon.png" class="pic">
                <figcaption>Edit Prompt: "a hot air balloon"</figcaption>
            </figure>
        </div>

        <h4>1.8 Visual Anagrams</h4>

        <p>
            
        </p>

        



    </main>

    <footer>
        <p>&copy; 2025 Yiqin Huang. All rights reserved.</p>
    </footer>
</body>
</html>